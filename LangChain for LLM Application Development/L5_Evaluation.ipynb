{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruqyai/LangChain-Models-Prompts-and-Output-Parsers-DeepLearning.ai/blob/main/L5_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52824b89-532a-4e54-87e9-1410813cd39e",
      "metadata": {
        "id": "52824b89-532a-4e54-87e9-1410813cd39e"
      },
      "source": [
        "# LangChain: Evaluation\n",
        "\n",
        "## Outline:\n",
        "\n",
        "* Example generation\n",
        "* Manual evaluation (and debuging)\n",
        "* LLM-assisted evaluation\n",
        "* LangChain evaluation platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
      "metadata": {
        "tags": [],
        "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "945d8abb-ba55-40a4-a3c5-6ad0dab73e3e",
      "metadata": {
        "id": "945d8abb-ba55-40a4-a3c5-6ad0dab73e3e"
      },
      "source": [
        "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ff81cd-dce0-4344-8d45-4a98fd3a87c9",
      "metadata": {
        "id": "24ff81cd-dce0-4344-8d45-4a98fd3a87c9"
      },
      "outputs": [],
      "source": [
        "# account for deprecation of LLM model\n",
        "import datetime\n",
        "# Get the current date\n",
        "current_date = datetime.datetime.now().date()\n",
        "\n",
        "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
        "target_date = datetime.date(2024, 6, 12)\n",
        "\n",
        "# Set the model variable based on the current date\n",
        "if current_date > target_date:\n",
        "    llm_model = \"gpt-3.5-turbo\"\n",
        "else:\n",
        "    llm_model = \"gpt-3.5-turbo-0301\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28008949",
      "metadata": {
        "id": "28008949"
      },
      "source": [
        "## Create our QandA application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
      "metadata": {
        "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.vectorstores import DocArrayInMemorySearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec1106d",
      "metadata": {
        "id": "9ec1106d"
      },
      "outputs": [],
      "source": [
        "file = 'OutdoorClothingCatalog_1000.csv'\n",
        "loader = CSVLoader(file_path=file)\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b31c218f",
      "metadata": {
        "id": "b31c218f"
      },
      "outputs": [],
      "source": [
        "index = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=DocArrayInMemorySearch\n",
        ").from_loaders([loader])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2006054",
      "metadata": {
        "id": "a2006054"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=index.vectorstore.as_retriever(),\n",
        "    verbose=True,\n",
        "    chain_type_kwargs = {\n",
        "        \"document_separator\": \"<<<<>>>>>\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791ebd73",
      "metadata": {
        "id": "791ebd73"
      },
      "source": [
        "### Coming up with test datapoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb04a0f9",
      "metadata": {
        "id": "fb04a0f9"
      },
      "outputs": [],
      "source": [
        "data[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4a88c2",
      "metadata": {
        "id": "fe4a88c2"
      },
      "outputs": [],
      "source": [
        "data[11]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d548aef",
      "metadata": {
        "id": "8d548aef"
      },
      "source": [
        "### Hard-coded examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d59bf2",
      "metadata": {
        "id": "c2d59bf2"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"query\": \"Do the Cozy Comfort Pullover Set\\\n",
        "        have side pockets?\",\n",
        "        \"answer\": \"Yes\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What collection is the Ultra-Lofty \\\n",
        "        850 Stretch Down Hooded Jacket from?\",\n",
        "        \"answer\": \"The DownTek collection\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7ce3e4f",
      "metadata": {
        "id": "c7ce3e4f"
      },
      "source": [
        "### LLM-Generated examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d44f8376",
      "metadata": {
        "id": "d44f8376"
      },
      "outputs": [],
      "source": [
        "from langchain.evaluation.qa import QAGenerateChain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e87816",
      "metadata": {
        "id": "34e87816"
      },
      "outputs": [],
      "source": [
        "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fb5bd0-fc2a-478c-9a09-6fe7e3307241",
      "metadata": {
        "id": "31fb5bd0-fc2a-478c-9a09-6fe7e3307241"
      },
      "outputs": [],
      "source": [
        "# the warning below can be safely ignored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62abae09",
      "metadata": {
        "id": "62abae09"
      },
      "outputs": [],
      "source": [
        "new_examples = example_gen_chain.apply_and_parse(\n",
        "    [{\"doc\": t} for t in data[:5]]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97ab28b5",
      "metadata": {
        "id": "97ab28b5"
      },
      "outputs": [],
      "source": [
        "new_examples[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ebe4228",
      "metadata": {
        "id": "0ebe4228"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf25f2f",
      "metadata": {
        "id": "faf25f2f"
      },
      "source": [
        "### Combine examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada2a3fc",
      "metadata": {
        "id": "ada2a3fc"
      },
      "outputs": [],
      "source": [
        "examples += new_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cdf5cf5",
      "metadata": {
        "id": "9cdf5cf5"
      },
      "outputs": [],
      "source": [
        "qa.run(examples[0][\"query\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63f3cb08",
      "metadata": {
        "id": "63f3cb08"
      },
      "source": [
        "## Manual Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcaf622e",
      "metadata": {
        "id": "fcaf622e"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "langchain.debug = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a142638",
      "metadata": {
        "id": "8a142638"
      },
      "outputs": [],
      "source": [
        "qa.run(examples[0][\"query\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d6bef0",
      "metadata": {
        "id": "b3d6bef0"
      },
      "outputs": [],
      "source": [
        "# Turn off the debug mode\n",
        "langchain.debug = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5bdbdce",
      "metadata": {
        "id": "d5bdbdce"
      },
      "source": [
        "## LLM assisted evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4dca05a",
      "metadata": {
        "id": "a4dca05a"
      },
      "outputs": [],
      "source": [
        "predictions = qa.apply(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6012a3e0",
      "metadata": {
        "id": "6012a3e0"
      },
      "outputs": [],
      "source": [
        "from langchain.evaluation.qa import QAEvalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "724b1c0b",
      "metadata": {
        "id": "724b1c0b"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, model=llm_model)\n",
        "eval_chain = QAEvalChain.from_llm(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b46ae55",
      "metadata": {
        "id": "8b46ae55"
      },
      "outputs": [],
      "source": [
        "graded_outputs = eval_chain.evaluate(examples, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3437cfbe",
      "metadata": {
        "id": "3437cfbe"
      },
      "outputs": [],
      "source": [
        "for i, eg in enumerate(examples):\n",
        "    print(f\"Example {i}:\")\n",
        "    print(\"Question: \" + predictions[i]['query'])\n",
        "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
        "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
        "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95133bb-43b6-441d-9ba5-00ef5609ccc8",
      "metadata": {
        "id": "d95133bb-43b6-441d-9ba5-00ef5609ccc8"
      },
      "outputs": [],
      "source": [
        "graded_outputs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad0ddd1",
      "metadata": {
        "id": "fad0ddd1"
      },
      "source": [
        "## LangChain evaluation platform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef63bb24",
      "metadata": {
        "id": "ef63bb24"
      },
      "source": [
        "The LangChain evaluation platform, LangChain Plus, can be accessed here https://www.langchain.plus/.  \n",
        "Use the invite code `lang_learners_2023`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b95a2e-3bc7-429a-83af-387239e7f2a1",
      "metadata": {
        "id": "35b95a2e-3bc7-429a-83af-387239e7f2a1"
      },
      "source": [
        "Reminder: Download your notebook to you local computer to save your work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be5b2aae",
      "metadata": {
        "id": "be5b2aae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "319798ba",
      "metadata": {
        "id": "319798ba"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a504ad",
      "metadata": {
        "id": "89a504ad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dedd758b",
      "metadata": {
        "id": "dedd758b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36885b20",
      "metadata": {
        "id": "36885b20"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c6cfb6",
      "metadata": {
        "id": "65c6cfb6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ad3c7cc",
      "metadata": {
        "id": "9ad3c7cc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ac493e",
      "metadata": {
        "id": "26ac493e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f94cdacd",
      "metadata": {
        "id": "f94cdacd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}